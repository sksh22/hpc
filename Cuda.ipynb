{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VhcIAk6U8Trg",
    "outputId": "edc1aac6-4a3c-43a2-fd05-d2eb883e1428"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvcc' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'nvidia-smi' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version\n",
    "!nvidia-smi //NVIDIA System Management Interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FWx6q7MUfwet",
    "outputId": "7956bc01-0142-4b50-b2b1-d92e371a67fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing add.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile add.cu\n",
    "#include <iostream>\n",
    "#include <cstdlib>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "#define N 4\n",
    "\n",
    "__global__ void add(int* A, int* B, int* C, int size) {\n",
    "\\global thread ID",
    "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n ",
    "    if (tid < size) {\n",
    "        C[tid] = A[tid] + B[tid];\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int A[N], B[N], C[N];\n",
    "\n",
    "    // Initialize input arrays\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        A[i] = rand() % 10;\n",
    "        B[i] = rand() % 10;\n",
    "    }\n",
    "\n",
    "    // Print input arrays\n",
    "    std::cout << \"A: \";\n",
    "    for (int i = 0; i < N; i++) std::cout << A[i] << \" \";\n",
    "    std::cout << \"\\nB: \";\n",
    "    for (int i = 0; i < N; i++) std::cout << B[i] << \" \";\n",
    "    std::cout << std::endl;\n",
    "\n",
    "    // Allocate device memory\n",
    "    int *dA, *dB, *dC;\n",
    "    size_t bytes = N * sizeof(int);\n",
    "    cudaMalloc(&dA, bytes);\n",
    "    cudaMalloc(&dB, bytes);\n",
    "    cudaMalloc(&dC, bytes);\n",
    "\n",
    "    // Copy data to device\n",
    "    cudaMemcpy(dA, A, bytes, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(dB, B, bytes, cudaMemcpyHostToDevice);\n",
    "\n",
    "    // Launch kernel\n",
    "    int threadsPerBlock = 256;\n",
    "    //Number of blocks needed to cover all N elements.",
    "    int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;\n", 
    "    //Launches the add kernel on GPU.",
    "    add<<<blocksPerGrid, threadsPerBlock>>>(dA, dB, dC, N);\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "    // Copy result back\n",
    "    cudaMemcpy(C, dC, bytes, cudaMemcpyDeviceToHost);\n",
    "\n",
    "    // Print result\n",
    "    std::cout << \"C: \";\n",
    "    for (int i = 0; i < N; i++) std::cout << C[i] << \" \";\n",
    "    std::cout << std::endl;\n",
    "\n",
    "    // Cleanup\n",
    "    cudaFree(dA);\n",
    "    cudaFree(dB);\n",
    "    cudaFree(dC);\n",
    "\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uBaqwvDzhDSE"
   },
   "source": [
    "When compiling with nvcc, specify the correct target architecture for the GPU you're using. Use either -arch=sm_70 or -arch=sm_60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-B3vv6avgUGC",
    "outputId": "5bc0be1c-1d41-4502-c0d1-1c65b45bd4f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: 3 7 3 6 \n",
      "B: 6 5 5 2 \n",
      "C: 9 12 8 8 \n"
     ]
    }
   ],
   "source": [
    "!nvcc -arch=sm_70 add.cu -o add\n",
    "!./add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "96FCHchhYm8T",
    "outputId": "aee59cf8-f8de-4a9f-d65c-e19c82afd3db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing matrix.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile matrix.cu\n",
    "#include <iostream>\n",
    "#define N 4\n",
    "\n",
    "__global__ void matrixMul(int *A, int *B, int *C, int n) {\n",
    "    int row = threadIdx.y + blockIdx.y * blockDim.y;\n",
    "    int col = threadIdx.x + blockIdx.x * blockDim.x;\n",
    "\n",
    "    if (row < n && col < n) {\n",
    "        int sum = 0;\n",
    "        for (int k = 0; k < n; k++)\n",
    "            sum += A[row * n + k] * B[k * n + col];\n",
    "        C[row * n + col] = sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int A[N*N], B[N*N], C[N*N];\n",
    "    for (int i = 0; i < N*N; i++) {\n",
    "        A[i] = i;\n",
    "        B[i] = i;\n",
    "    }\n",
    "\n",
    "    int *dA, *dB, *dC;\n",
    "    size_t bytes = N * N * sizeof(int);\n",
    "    cudaMalloc(&dA, bytes);\n",
    "    cudaMalloc(&dB, bytes);\n",
    "    cudaMalloc(&dC, bytes);\n",
    "\n",
    "    cudaMemcpy(dA, A, bytes, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(dB, B, bytes, cudaMemcpyHostToDevice);\n",
    "\n",
    "    dim3 threads(16, 16);\n",
    "    dim3 blocks((N + 15) / 16, (N + 15) / 16);\n",
    "    matrixMul<<<blocks, threads>>>(dA, dB, dC, N);\n",
    "    cudaMemcpy(C, dC, bytes, cudaMemcpyDeviceToHost);\n",
    "\n",
    "    std::cout << \"Matrix C:\\n\";\n",
    "    for (int i = 0; i < N * N; i++) {\n",
    "        std::cout << C[i] << \" \";\n",
    "        if ((i + 1) % N == 0) std::cout << \"\\n\";\n",
    "    }\n",
    "\n",
    "    cudaFree(dA);\n",
    "    cudaFree(dB);\n",
    "    cudaFree(dC);\n",
    "\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NRUQWgEIYwqN",
    "outputId": "351ae27d-3747-4271-e6bf-134b1348d1b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix C:\n",
      "56 62 68 74 \n",
      "152 174 196 218 \n",
      "248 286 324 362 \n",
      "344 398 452 506 \n"
     ]
    }
   ],
   "source": [
    "!nvcc -arch=sm_70 matrix.cu -o matrix\n",
    "!./matrix"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
